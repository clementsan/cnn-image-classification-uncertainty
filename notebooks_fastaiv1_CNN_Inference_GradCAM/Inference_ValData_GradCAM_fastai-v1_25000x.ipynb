{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #  fastai-v1  inference on Validation data - GradCAM experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup CUDA_VISIBLE DEVICES for titan.sci.utah.edu\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries - fastai_v1\n",
    "\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "from gradcam import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I/O and hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters and hyper-parameters\n",
    "\n",
    "# CSV file contains test dataset only (synthetic data)\n",
    "csv_test_FileName = 'Dataset_TargetClass_Overlap-9Blocks_25000xOnly_shuffled_fastai-v1_val.csv'\n",
    "csv_test = os.path.join('../CSV_InputFiles_TargetClass',csv_test_FileName)\n",
    "\n",
    "csv_result = os.path.join(os.getcwd(),'Dataset_TargetClass_Overlap-9Blocks_25000xOnly_shuffled_fastai-v1_val-Prediction.csv')\n",
    "\n",
    "csv_result_MajVoting = os.path.join(os.getcwd(),'Dataset_TargetClass_Overlap-9Blocks_25000xOnly_shuffled_fastai-v1_val-Prediction_MajVoting.csv')\n",
    "\n",
    "# Network\n",
    "model_path = os.path.join(os.getcwd(),'models')\n",
    "model_file = ('TargetClass_fastai-v1_224_all_resnet50.pkl')\n",
    "\n",
    "# Network architecture\n",
    "arch = models.resnet50\n",
    "# Image size\n",
    "sz = 224\n",
    "# Batch size\n",
    "bs = 32\n",
    "# Default learning rate\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv file and create dataframe\n",
    "df_test = pd.read_csv(csv_test, sep=',')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.groupby(['Label']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_size = df_test.groupby(['Label']).size()\n",
    "#df_test_size = df_test_size.reindex(classes_Labels_ordered)\n",
    "df_test_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate bar graph\n",
    "# pd.value_counts(df_test['Label']).sort_index().plot(kind='bar', title = 'Starting Material - test dataset')\n",
    "# fig1 = plt.gcf()\n",
    "# plt.tight_layout()\n",
    "# fig1.savefig('BarGraph_Distribution_StartingMaterial_TestData.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns_plot = sns.countplot(x=\"Label\", data=df_test)\n",
    "sns_plot.set_xticklabels(sns_plot.get_xticklabels(), rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig = sns_plot.get_figure()\n",
    "fig.savefig(\"BarGraph_Distribution_TargetClass_ValData.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference - Test dataset - without TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ImageList.from_csv(os.getcwd(), csv_test_FileName, folder='../Data_TargetClass')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main commands to load data and model\n",
    "learn = load_learner(model_path,model_file, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test, _, losses = learn.get_preds(ds_type=DatasetType.Test,with_loss=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_classes = [learn.data.classes[np.argmax(pred)] for pred in y_pred_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred_test[0])\n",
    "print(y_pred_test[0].numpy())\n",
    "print(np.sum(y_pred_test[0].numpy()))\n",
    "print(np.argmax(y_pred_test[0]))\n",
    "print(y_pred_test_classes[0])\n",
    "print(losses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred_test_classes[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FileNames = [i.split('/', -1)[-1] for i in learn.data.test_ds.items]\n",
    "FileNames = ['/'.join(i.split('/', -1)[-4:]) for i in learn.data.test_ds.items]\n",
    "print(FileNames[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for prediction on test data\n",
    "df_preds_test = pd.DataFrame({'File':FileNames, 'Prediction':y_pred_test_classes})\n",
    "df_preds_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df_test.merge(df_preds_test,on='File',how='left')\n",
    "result.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results as CSV file\n",
    "result.to_csv(csv_result, index=False, na_rep = 'NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ClassificationIntepretation object. \n",
    "interp = ClassificationInterpretation.from_learner(learn,ds_type=DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.most_confused()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.iloc[0]['File']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = os.path.join('../Data_TargetClass/',result.iloc[0]['File'])\n",
    "print(test_img)\n",
    "img = open_image(test_img);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gcam = GradCam.from_one_img(learn,img)\n",
    "gcam.plot(plot_hm=True,plot_gbp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_Labels_ordered = learn.data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "# Find first element for each distinct predicted class\n",
    "# plot gradCAM\n",
    "for pred_class in classes_Labels_ordered:\n",
    "    print(pred_class)\n",
    "    pred_class_idx_list = result[result['Prediction']==pred_class].index.values\n",
    "    # Pick random element\n",
    "    pred_class_idx = random.choice(pred_class_idx_list)\n",
    "    #print(pred_class_idx)\n",
    "    File = result.iloc[pred_class_idx]['File']\n",
    "    #print(File)\n",
    "    test_img = os.path.join('../Data_TargetClass',File)\n",
    "    #print(test_img)\n",
    "    img = open_image(test_img);\n",
    "    gcam = GradCam.from_one_img(learn,img)\n",
    "    gcam.plot(plot_hm=True,plot_gbp=False)\n",
    "    fig=plt.gcf()\n",
    "    FigTitle = './GradCAM_Example_' + pred_class + '.png'\n",
    "    fig.savefig(FigTitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def plot_gradCAM_examples_correct(pred_class, nb=4):\n",
    "    pred_class_idx_list_all = result[result['Prediction']==pred_class].index.values\n",
    "    # Pick random nb elements\n",
    "    pred_class_idx_list = random.choices(pred_class_idx_list_all,k=2*nb)\n",
    "    counter = 0 \n",
    "    for pred_class_idx in pred_class_idx_list:\n",
    "        #print(pred_class_idx)\n",
    "        Pred_Label = result.iloc[pred_class_idx]['Prediction']\n",
    "        Actual_Label = result.iloc[pred_class_idx]['Label']\n",
    "        if (Pred_Label == Actual_Label):\n",
    "            counter += 1\n",
    "            File = result.iloc[pred_class_idx]['File']\n",
    "            #print(File)\n",
    "            test_img = os.path.join('../Data_TargetClass',File)\n",
    "            #print(test_img)\n",
    "            img = open_image(test_img);\n",
    "            gcam = GradCam.from_one_img(learn,img)\n",
    "            gcam.plot(plot_hm=True,plot_gbp=False)\n",
    "            fig=plt.gcf()\n",
    "            FigTitle = './GradCAM-CorrectPred_' + pred_class + '_Example' + str(counter) + '.png'\n",
    "            fig.savefig(FigTitle)\n",
    "        else:\n",
    "            print('Incorrect Prediction') \n",
    "        if (counter == nb):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot gradCAM of first 4 elements for a specific predicted class\n",
    "for label in classes_Labels_ordered:\n",
    "    plot_gradCAM_examples_correct(label,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def plot_gradCAM_examples_incorrect(pred_class, nb=4):\n",
    "    pred_class_idx_list_all = result[result['Prediction']==pred_class].index.values\n",
    "    # Pick random nb elements\n",
    "    pred_class_idx_list = random.choices(pred_class_idx_list_all,k=len(pred_class_idx_list_all))\n",
    "    counter = 0 \n",
    "    for pred_class_idx in pred_class_idx_list:\n",
    "        #print(pred_class_idx)\n",
    "        Pred_Label = result.iloc[pred_class_idx]['Prediction']\n",
    "        Actual_Label = result.iloc[pred_class_idx]['Label']\n",
    "        if (Pred_Label != Actual_Label):\n",
    "            counter += 1\n",
    "            File = result.iloc[pred_class_idx]['File']\n",
    "            #print(File)\n",
    "            test_img = os.path.join('../Data_TargetClass',File)\n",
    "            #print(test_img)\n",
    "            img = open_image(test_img);\n",
    "            gcam = GradCam.from_one_img(learn,img, label1=Pred_Label, label2=Actual_Label)\n",
    "            gcam.plot(plot_hm=True,plot_gbp=False)\n",
    "            fig=plt.gcf()\n",
    "            FigTitle = './GradCAM-IncorrectPred_' + pred_class + '_Example' + str(counter) + '.png'\n",
    "            fig.savefig(FigTitle)\n",
    "        #else:\n",
    "            #print('Incorrect Prediction') \n",
    "        if (counter == nb):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot gradCAM of first 4 elements for a specific predicted class\n",
    "for label in classes_Labels_ordered:\n",
    "    plot_gradCAM_examples_incorrect(label,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "266px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
